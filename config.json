{
	"reward_decay": 0.99,
	"seed": 0,
	"train_steps": 5000,
	"log_frequency": 200,
	"batch_size": 128,
	"experiment_name": "RecurrentA2C Test",
	"log_folder": "./logs",
	"actor_critic": {
		"embedding_size": 4,
		"input_layers": [36, 32],
		"lstm_size": 32,
		"actor_layers": [32, 64, 4],
		"critic_layers": [32, 64, 1]
	}
}